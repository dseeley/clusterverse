---

- name: "dynamic_inventory | Get cluster_hosts_state for {{cluster_vars.type}} cluster"
  include_role:
    name: 'clusterverse/cluster_hosts'
    tasks_from: "get_cluster_hosts_state_{{cluster_vars.type}}.yml"

- name: dynamic_inventory | assert that cluster_hosts_state is defined
  assert: { that: "cluster_hosts_state is defined", msg: "cluster_hosts_state is not defined" }

- name: dynamic_inventory | cluster_hosts_state
  debug: msg="{{cluster_hosts_state}}"

- name: dynamic_inventory | ansible_inventory_sources
  debug: msg="{{ansible_inventory_sources}}"

- name: dynamic_inventory | stat the ansible_inventory_sources paths
  stat: path={{item}}
  register: r__stat_inventory_sources
  with_items: "{{ansible_inventory_sources}}"
  when: ansible_inventory_sources is defined

- name: dynamic_inventory | r__stat_inventory_sources
  debug: msg="{{r__stat_inventory_sources}}"

- name: "Assert that only one non-existent inventory source is defined, and if there is, that it is defined to be in playbook_dir"
  assert:
    that: "((r__stat_inventory_sources.results | json_query('[?stat.exists==`false`]') | length == 0)  or  ((r__stat_inventory_sources.results | json_query('[?stat.exists==`false`]') | length == 1) and (r__stat_inventory_sources.results | json_query('[?stat.exists==`false`].item | [0]') | dirname == playbook_dir)) )"
    fail_msg: "Only a single non-existent inventory source may be defined, and if there is, it must be defined to be in playbook_dir; (ansible_inventory_sources: {{r__stat_inventory_sources.results | json_query('[?stat.exists==`false`].item')}}).  CHECK: Is 'inventory = _dynamic_inventory' set in ansible.cfg?"

- name: dynamic_inventory | Check whether we're using a manually-defined (or multiply-defined) static inventory
  warn_str:
    msg: "WARNING: Static inventory file(s) in use - cannot gather dynamic inventory: {{ r__stat_inventory_sources.results | json_query(\"[?stat.isreg].item \") }}"
  when: r__stat_inventory_sources.results | json_query('[?stat.isreg].item') | length

- block:
    - name: dynamic_inventory | create the inventory_source directory
      ansible.builtin.file:
        path: "{{inventory_source}}"
        state: directory
        mode: '0755'

    - name: dynamic_inventory | Get (network) facts - to determine the local IP/network, to see if we need the bastion below (requires the 'ip' tool (the 'iproute2' package on Ubuntu))
      ansible.builtin.setup: { gather_subset: ["network"] }

    - name: dynamic_inventory | Add (powered-on) hosts to dynamic inventory
      set_fact:
        dynamic_inv: |
          {% set res = [] -%}
          {%- for item in cluster_hosts_state | json_query('[?contains([\'RUNNING\',\'running\',\'poweredOn\'], instance_state)]') | sort(attribute='name') -%}
            {%- set _dummy = res.append({
                'name': item.name,
                'groups': [item.tagslabels.hosttype] + [cluster_name] + ([clusterid] if clusterid is defined and clusterid else []) + ([item.regionzone] if item.regionzone is defined and item.regionzone else []) + (['not_target_hosts'] if cluster_hosts_target is defined and item.name not in (cluster_hosts_target | default({}) | map(attribute='hostname')) else []),
                'ansible_host': item.ipv4.public if cluster_vars.inventory_ip=='public' else item.ipv4.private,
                'ipv4_private': item.ipv4.private,
                'hosttype': item.tagslabels.hosttype
              }) -%}
            {%- set _dummy = res[res | length-1].update({'regionzone': item.regionzone})  if item.regionzone else '' -%}
            {%- set _dummy = res[res | length-1].update({'ansible_user': cluster_vars[buildenv].ssh_connection_cfg.host.ansible_user})  if cluster_vars[buildenv].ssh_connection_cfg.host.ansible_user else '' -%}
            {%- set _dummy = res[res | length-1].update({'ipv4_public': item.ipv4.public})  if 'assign_public_ip' in cluster_vars and cluster_vars.assign_public_ip in [true, 'dynamic', 'static'] else '' -%}
            {%- set _dummy = res[res | length-1].update({'ansible_ssh_private_key_file': 'id_rsa_ansible_ssh_private_key_file'})  if cluster_vars[buildenv].ssh_connection_cfg.host.ansible_ssh_private_key_file else '' -%}
            {%- set _dummy = res[res | length-1].update({'ansible_ssh_common_args': cluster_vars[buildenv].ssh_connection_cfg.bastion.ssh_args})  if _bastion_host and (not _bastion_in_host_net or (force_use_bastion is defined and force_use_bastion|bool)) else '' -%}
            {%- endfor -%}
            {{ res }}
      vars:
        _local_cidr: "{{ (ansible_default_ipv4.network+'/'+ansible_default_ipv4.netmask) | ansible.utils.ipaddr('network/prefix') }}"                                 # Get the network the localhost IP is in
        _bastion_host: "{{ cluster_vars[buildenv].ssh_connection_cfg.bastion.ssh_args | default() | regex_replace('.*@([]\\w\\d\\.-]*).*', '\\1') }}"                 # Extract just the bastion hostname from 'cluster_vars[buildenv].ssh_connection_cfg.bastion.ssh_args'
        _bastion_in_host_net: "{{ query('dig', _bastion_host, errors='ignore') | map('ansible.utils.ipaddr', _local_cidr) | select() | list | length > 0 }}"          # Check each bastion IP (there could be multiple results from the 'dig'), and see they're in the _local_cidr range.

    - name: dynamic_inventory | dynamic_inv
      debug: msg="{{ dynamic_inv }}"

    - name: dynamic_inventory | Populate (or delete) inventory files
      block:
        - name: dynamic_inventory | Populate inventory file from dynamic inventory (if not empty)
          copy:
            content: |
              {% set groups = dynamic_inv | json_query('[].groups|[]') | unique | sort() %}
              {% for groupname in groups -%}
              [{{ groupname }}]
              {% for host in dynamic_inv | json_query('[?contains(groups, \'' + groupname + '\')]') %}
              {{ host['name'] }} ansible_host={{host['ansible_host']}} {% if 'ipv4_public' in host %}ipv4_public={{ host['ipv4_public'] }}{% endif %} ipv4_private={{ host['ipv4_private'] }} hosttype={{ host['hosttype'] }} {% if 'ansible_user' in host %}ansible_user='{{ host['ansible_user'] }}'{% endif %} {% if 'ansible_ssh_private_key_file' in host %}ansible_ssh_private_key_file='{{ host['ansible_ssh_private_key_file'] }}'{% endif %} {% if 'regionzone' in host %}regionzone={{ host['regionzone'] }}{% endif %} {% if 'ansible_ssh_common_args' in host %}ansible_ssh_common_args='{{ host['ansible_ssh_common_args'] }}'{% endif %}{{''}}
              {% endfor %}
              
              {% endfor %}
            dest: "{{item}}"
            force: yes
          with_items: "{{inventory_files}}"
          when: dynamic_inv | length

        - name: dynamic_inventory | Delete inventory files if inventory is zero-length
          file:
            state: absent
            path: "{{item}}"
          with_items: "{{inventory_files}}"
          when: dynamic_inv | length == 0
      vars:
        inventory_files: ["{{inventory_source}}/{{cur_inventory_filename}}", "{{playbook_dir}}/{{cur_inventory_filename}}"]

    - name: dynamic_inventory | Create inventory deletion script
      copy:
        content: |
          #!/usr/bin/env python3

          import os, sys, json

          inventory_filename = "{{cur_inventory_filename}}"
          script_directory = os.path.dirname(os.path.abspath(__file__))
          script_filename = os.path.basename(__file__)

          try:
              for filename in os.listdir(script_directory):
                  if filename not in [inventory_filename, script_filename]:
                      file_path = os.path.join(script_directory, filename)
                      if os.path.isfile(file_path):
                          os.remove(file_path)
          except Exception as e:
              sys.stderr.write("An error occurred: " + str(e) + "\n")
              sys.exit(1)

          print(json.dumps({'_meta': {'hostvars': {}}}))
        mode: 0755
        dest: "{{inventory_source}}/00-delete-non-inventory-files.py"
        force: yes

      # NOTE: if the file lookup error handler is called, it returns a NoneType, which the split() filter cannot understand - hence the ternary.
    - name: dynamic_inventory | inventory file contents
      debug: msg="{{ ((lookup('file', inventory_source+'/'+cur_inventory_filename, errors='ignore') | type_debug=='NoneType') | ternary('', lookup('file', inventory_source+'/'+cur_inventory_filename, errors='ignore'))).split('\n') | map('trim') }}"
  vars:
    cur_inventory_filename: "inventory__{{ app_name + ('-' + cloud_type if cloud_type is defined and cloud_type else '') + ('-' + clusterid if clusterid is defined and clusterid else '') + ('-' + region if region is defined and region else '') + ('-' + buildenv if buildenv is defined and buildenv else '') }}"
    inventory_source: "{{ansible_inventory_sources[0]}}"
  when: ((r__stat_inventory_sources.results | json_query('[?stat.exists]') | length == 0) and (ansible_inventory_sources | length == 1))  or  ((r__stat_inventory_sources.results | json_query('[?stat.exists]') | length == 1)  and  (r__stat_inventory_sources.results | json_query('[?stat.isdir]') | length == 1))

  #Note: Ideally this refresh_inventory would only be called within the 'when' clause, but refresh_inventory does not support 'when', and it causes a warning.
- name: dynamic_inventory | Refresh the inventory (with the dynamically created inventory, if applicable)
  meta: refresh_inventory

- name: dynamic_inventory | current inventory_hostnames
  debug: msg="{{ query('inventory_hostnames','all', errors='ignore') | sort() }}"


### Ideally, we would like to verify that each host is contactable at this point.  However, no combination of the normal Ansible modules allow this.
### Note: This play is running on localhost only - not on the remotes.
#   + The 'wait_for' module cannot reliably wait for a usable ansible ssh pipeline to be created - it can only wait for the tcp ssh port to be open.  Neither can it can reliably search for a regex,
#     as the response differs between VM flavours.  Most importantly, it does not work behind a bastion host (the 'host' field is waited on from localhost, not the the host through the bastion).
#   + The 'ping' module (used below), can be told to be delegated to a remote host, which means (as normal), that the module is sent to the remote, and from there, checks
#     for a connection to localhost.  This is a problem, because it cannot do this if the remote is not yet ready; it will wait for a short time, but often, not long enough (esp on RHEL
#     or BSD VMs).  It *should* be possible to do {register: / until: / retries:}, but this does not work - once the connection fails for the first time, retries are not performed.
#   + The 'wait_for_connection' module cannot be made to wait for a connection to a delegated host (https://github.com/ansible/ansible/issues/36519), so in this play it can only wait for the connection
#     to localhost, which is of no value.  The only reliable solution for slow-to-create VMs appears to be to put 'wait_for_connection' in a new play, which runs per-host (i.e. from cluster.yml).
- block:
    - name: dynamic_inventory | Wait for SSH connectivity (using reverse-delegated ping.  Deprecated.)
      ping:
      delegate_to: "{{ item }}"
      with_items: "{{ groups['all'] }}"
      failed_when: false
      ignore_unreachable: yes
      ignore_errors: yes
    - meta: clear_host_errors
    - deprecate_str: { msg: "Waiting for SSH connectivity using 'ping' is unreliable and thus deprecated (see comment in roles/clusterverse/dynamic_inventory/tasks/main.yml).  Please use 'wait_for_connection' in the top-level cluster.yml (see roles/clusterverse/EXAMPLE/cluster.yml)" }
  when: skip_dynamic_inventory_sshwait is not defined or (skip_dynamic_inventory_sshwait|bool == false)
