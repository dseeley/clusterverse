---

- name: Load cluster definitions
  block:
    - block:
        - name: Derive cluster definitions by merging tiered configuration files
          merge_vars:
            from: "{{ merge_dict_vars_list }}"
            ignore_missing_files: True

#        - name: Loaded/derived/overridden cluster_vars
#          debug: msg="{{cluster_vars}}"
      when: merge_dict_vars_list is defined and merge_dict_vars_list | length > 0

    - block:
        - name: Load native cluster definitions by forcing include of group_vars on localhost (no inventory yet, so cannot import automatically)
          include_vars: { dir: "{{ playbook_dir }}/group_vars/{{ clusterid }}" }

        - deprecate_str: { msg: "Loading variables via group_vars/clusterid is deprecated.  Please use merge_vars via cluster_defs in future" }
      when: merge_dict_vars_list is not defined  and  clusterid is defined

    - name: argv
      debug: msg={{ argv }}

    - name: cluster_vars_override
      debug: msg={{cluster_vars_override}}
      when: cluster_vars_override is defined

    - name: Combine command-line cluster_vars_override into the loaded cluster_vars
      set_fact:
        cluster_vars: "{{cluster_vars | combine({item.key: item.value | from_yaml}, recursive=True)}}"      # Do the combine with individually parsed variables, because sometimes, the 'value' field of an individual dict is still a string (e.g. during redeploy, which passes the cluster_vars_override again).
      vars:
        _cluster_vars_override_templated: "{{ cluster_vars_override | default({}) }}"                       #This pre-templating technique is needed because sometimes the command-line is interpolated as a string, sometimes as a dict - this normalises it as a dict (which the 'combine' filter, above, requires), however the nested parameters may *still* be stringified (as above).
      with_dict: "{{_cluster_vars_override_templated}}"
      when: cluster_vars is defined and cluster_vars_override is defined and cluster_vars_override != ''


- name: Get AWS STS credentials if required
  block:
    - assert: { that: "cluster_vars[buildenv].aws_secret_key is not defined or cluster_vars[buildenv].aws_secret_key == ''", fail_msg: "aws_secret_key and aws_sts_assume_role_arn cannot both be set." }
      when: cluster_vars.type == "aws"

    - name: sts_assume_role
      community.aws.sts_assume_role:
        role_arn: "{{cluster_vars[buildenv].aws_sts_assume_role_arn}}"
        role_session_name: "ansible__{{cluster_vars[buildenv].aws_sts_assume_role_arn | basename }}__{{cluster_name}}"
      register: r__sts_assume_role

    - name: update cluster_vars[buildenv].aws_access_key and cluster_vars[buildenv].aws_secret_key
      set_fact:
        cluster_vars: "{{cluster_vars | combine({buildenv: {'aws_access_key': r__sts_assume_role.sts_creds.access_key, 'aws_secret_key': r__sts_assume_role.sts_creds.secret_key, 'aws_session_token': r__sts_assume_role.sts_creds.session_token }}, recursive=True)}}"

    - name: debug cluster_vars[buildenv].aws_access_key
      debug:
        msg:
           - "{{cluster_vars[buildenv].aws_access_key}}"
           - "{{cluster_vars[buildenv].aws_secret_key}}"
           - "{{cluster_vars[buildenv].aws_session_token}}"
  when: cluster_vars.type == "aws" and cluster_vars[buildenv].aws_sts_assume_role_arn is defined and cluster_vars[buildenv].aws_sts_assume_role_arn != ''

- name: Preflight check
  block:
    - name: Ansible requirement
      assert:
        that: "ansible_version.full is version('2.12.4', '>=')"
        fail_msg: "ansible-core 2.12.4 (pypi v5.6.0) is required."

    - name: assertions based on required collections
      block:
        - name: dseeley.nested_playbook is required for redeploys
          assert: { that: "'dseeley.nested_playbook' in galaxy_collections", fail_msg: "Please ensure the dseeley.nested_playbook collection is installed:  ansible-galaxy collection install dseeley.nested_playbook (or ansible-galaxy collection install --ignore-errors -fr requirements.yml)" }

        - name: libvirt collection requirements
          block:
            - assert: { that: "galaxy_collections['community.libvirt'].version is version('1.2.0', '>=')", fail_msg: "community.libvirt > 1.2.0 required for libvirt support (default in Ansible >= 6.3.0)." }
            - assert: { that: "'dseeley.libvirt' in galaxy_collections", fail_msg: "Please ensure the dseeley.libvirt collection is installed:  ansible-galaxy collection install git+https://github.com/dseeley/libvirt.git (or ansible-galaxy collection install --ignore-errors -fr requirements.yml)" }
            - assert: { that: "'dseeley.inventory_lookup' in galaxy_collections", fail_msg: "Please ensure the dseeley.inventory_lookup collection is installed:  ansible-galaxy collection install dseeley.inventory_lookup (or ansible-galaxy collection install --ignore-errors -fr requirements.yml)" }
          when: cluster_vars.type == "libvirt"

        - name: esxifree collection requirements
          assert: { that: "'dseeley.esxifree_guest' in galaxy_collections", fail_msg: "Please ensure the dseeley.esxifree_guest collection is installed:  ansible-galaxy collection install dseeley.esxifree_guest (or ansible-galaxy collection install --ignore-errors -fr requirements.yml)" }
          when: cluster_vars.type == "esxifree"
      vars:
        galaxy_collections: "{{lookup('pipe', 'ansible-galaxy collection list --format=json', errors='ignore') | from_json | json_query(\"*\") | combine }}"

    - assert: { that: "app_name is defined and app_name != ''", fail_msg: "Please define app_name" }
    - assert: { that: "app_class is defined and app_class != ''", fail_msg: "Please define app_class" }
    - assert: { that: "cluster_vars is defined", fail_msg: "Please define cluster_vars" }
    - assert: { that: "buildenv is defined and cluster_vars[buildenv] is defined", fail_msg: "Please define buildenv" }

      ## Tags/ labels must be compatible with GCP and AWS - check everything that goes into a label.
    - assert: { that: "release_version is regex('^[a-z\\d\\-_]{0,63}$')", fail_msg: "Please ensure release_version ({{release_version}}) is in the set [a-z\\d\\-_], and <63 characters long." }
      when: release_version is defined
    - assert: { that: "cluster_suffix is regex('^[a-z\\d\\-_]{0,63}$')", fail_msg: "Please ensure cluster_suffix ({{cluster_suffix}}) is in the set[a-z\\d\\-_], and <63 characters long." }
      when: cluster_suffix is defined
    - assert: { that: "'{%- for label in cluster_vars.custom_tagslabels -%}{% if not cluster_vars.custom_tagslabels[label] is regex('^[a-z\\d\\-_]{0,63}$') %}{{label}}: {{cluster_vars.custom_tagslabels[label]}}{% endif %}{%- endfor -%}' == ''", fail_msg: "Please ensure all cluster_vars.custom_tagslabels are in the set [a-z\\d\\-_], and <63 characters long." }
      when: "'custom_tagslabels' in cluster_vars"
    - assert: { that: "'{%- for hosttype in cluster_vars[buildenv].hosttype_vars -%}{% if ('version' in cluster_vars[buildenv].hosttype_vars[hosttype]) and (not cluster_vars[buildenv].hosttype_vars[hosttype].version is regex('^[a-z\\d\\-_]{0,63}$')) %}{{cluster_vars[buildenv].hosttype_vars[hosttype].version}}{% endif %}{%- endfor -%}' == ''", fail_msg: "Please ensure cluster_vars[{{buildenv}}].hosttype_vars[hosttype].version is in the set [a-z\\d\\-_], and <63 characters long." }

    - assert: { that: "(cluster_vars.inventory_ip == 'private')  or  (cluster_vars.assign_public_ip in [true, 'dynamic', 'static'] and cluster_vars.inventory_ip == 'public')", fail_msg: "If inventory_ip=='public', 'assign_public_ip' must be [true, 'dynamic', 'static']" }
      when: cluster_vars.type == "gcp" or cluster_vars.type == "aws"

    - assert: { that: "cluster_vars[buildenv] | json_query(\"hosttype_vars.*.auto_volumes[] | [?contains(`/dev/sdb,/dev/sdc,/dev/sdd,/dev/sde`, device_name) && volume_type!='ephemeral']\") | length == 0", fail_msg: "device_names /dev/sd[b-e] are only allowed for ephemeral volumes in AWS cluster_vars[buildenv].hosttype_vars.  Please start non-ephemeral devices at /dev/sdf." }
      when: cluster_vars.type == "aws"

    - assert:
        that: "'{%- for hosttype in cluster_vars[buildenv].hosttype_vars | dict2items -%}{%- if ('lvmparams' not in hosttype.value and (hosttype.value.auto_volumes | length) == (hosttype.value.auto_volumes | map(attribute='mountpoint') | list | unique | count))  or  ('lvmparams' in hosttype.value and (hosttype.value.auto_volumes | selectattr('mountpoint', '!=', '/') | map(attribute='mountpoint') | list | unique | count == 1)) -%}{%- else -%}{{hosttype.key}}{%- endif -%}{%- endfor -%}' == ''"
        fail_msg: "All non-root volume mountpoints must either be all different (in which case 'lvmparams' must not be set), or all the same (in which case, 'lvmparams' must be set)"

    - assert: { that: "cluster_vars[buildenv] | json_query(\"hosttype_vars.*.auto_volumes[] | [?iops > `16000`] && [?starts_with(volume_type, `gp`)]\") | length == 0", fail_msg: "Volume iops is too high; maximum is 16000" }
      when: cluster_vars.type == "aws"

- name: Create gcp service account contents file from cluster_vars[buildenv].gcp_service_account_rawtext (unless already defined by user)
  block:
    - name: "set gcp_credentials_file fact"
      set_fact:
        gcp_credentials_file: "gcp__{{ (cluster_vars[buildenv].gcp_service_account_rawtext if cluster_vars[buildenv].gcp_service_account_rawtext|type_debug == 'dict' else cluster_vars[buildenv].gcp_service_account_rawtext | string | from_json).project_id }}.json"
      when: gcp_credentials_file is not defined

    - name: stat the gcp_credentials_file
      stat: path={{gcp_credentials_file}}
      register: r__stat_gcp_credentials_file

    - name: "Copy credentials into gcp_credentials_file as {{gcp_credentials_file}}"
      local_action: copy content={{cluster_vars[buildenv].gcp_service_account_rawtext}} dest={{gcp_credentials_file}}
      when: not r__stat_gcp_credentials_file.stat.exists|default(False)|bool
  when: cluster_vars.type == "gcp"
